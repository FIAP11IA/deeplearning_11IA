{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "IMAGE_HEIGHT = 100\n",
    "IMAGE_WIDTH = 100\n",
    "IMAGE_CHANNELS = 3\n",
    "NETWORK_DEPTH = 4\n",
    "\n",
    "data_dir = os.getcwd() + \"/../input/\" \n",
    "data_dir += os.listdir(data_dir)[0] + \"/fruits-360/\"\n",
    "train_dir = data_dir + \"Training/\"\n",
    "validation_dir = data_dir + \"Test/\"\n",
    "\n",
    "batch_size = 60\n",
    "input_size = IMAGE_HEIGHT * IMAGE_WIDTH * NETWORK_DEPTH\n",
    "num_classes = len(os.listdir(train_dir))\n",
    "# probability to keep the values after a training iteration\n",
    "dropout = 0.8\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "final_learning_rate = 0.00001\n",
    "learning_rate = initial_learning_rate\n",
    "\n",
    "# number of iterations to run the training\n",
    "iterations = 75000\n",
    "# number of iterations after we display the loss and accuracy\n",
    "display_interval = 75000\n",
    "# default number of iterations after we save the model\n",
    "save_interval = 75000\n",
    "step_display = 15000\n",
    "# use the saved model and continue training\n",
    "useCkpt = False\n",
    "# placeholder for probability to keep the network parameters after an iteration\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# -------------------- Write/Read TF record logic --------------------\n",
    "class ImageCoder(object):\n",
    "    \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Create a single Session to run all image coding calls.\n",
    "        self._sess = tf.Session()\n",
    "\n",
    "        # Initializes function that decodes RGB JPEG data.\n",
    "        self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
    "        self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
    "\n",
    "    def decode_jpeg(self, image_data):\n",
    "        image = self._sess.run(self._decode_jpeg,\n",
    "                               feed_dict={self._decode_jpeg_data: image_data})\n",
    "        assert len(image.shape) == 3\n",
    "        assert image.shape[2] == 3\n",
    "        return image\n",
    "\n",
    "def write_image_data(dir_name, tfrecords_name):\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecords_name)\n",
    "    coder = ImageCoder()\n",
    "    image_count = 0\n",
    "    index = -1\n",
    "    classes_dict = {}\n",
    "\n",
    "    for folder_name in os.listdir(dir_name):\n",
    "        class_path = dir_name + '/' + folder_name + '/'\n",
    "        index += 1\n",
    "        classes_dict[index] = folder_name\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = class_path + image_name\n",
    "            image_count += 1\n",
    "            with tf.gfile.FastGFile(image_path, 'rb') as f:\n",
    "                image_data = f.read()\n",
    "                example = tf.train.Example(\n",
    "                    features = tf.train.Features(\n",
    "                        feature = {\n",
    "                            'label':tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),\n",
    "                            'image_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.compat.as_bytes(image_data)]))\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "                writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    print(classes_dict)\n",
    "    return image_count, classes_dict\n",
    "\n",
    "def build_datasets(train_file, test_file, batch_size):\n",
    "    train_dataset = tf.data.TFRecordDataset(train_file).repeat()\n",
    "    train_dataset = train_dataset.map(parse_single_example).map(lambda image, label: (augment_image(image), label))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    validation_dataset = tf.data.TFRecordDataset(train_file)\n",
    "    validation_dataset = validation_dataset.map(parse_single_example).map(lambda image, label: (build_hsv_grayscale_image(image), label))\n",
    "    validation_dataset = validation_dataset.batch(batch_size)\n",
    "    test_dataset = tf.data.TFRecordDataset(test_file)\n",
    "    test_dataset = test_dataset.map(parse_single_example).map(lambda image, label: (build_hsv_grayscale_image(image), label))\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    return train_dataset, validation_dataset, test_dataset\n",
    "    \n",
    "def parse_single_example(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    )\n",
    "    image = tf.image.decode_jpeg(features['image_raw'], channels=3)\n",
    "    image = tf.reshape(image, [100, 100, 3])\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    return image, label\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# -------------------- Network structure --------------------\n",
    "def conv(input_tensor, name, kernel_width, kernel_height, num_out_activation_maps, stride_horizontal=1, stride_vertical=1, activation_fn=tf.nn.relu):\n",
    "    prev_layer_output = input_tensor.get_shape()[-1].value\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('weights', [kernel_height, kernel_width, prev_layer_output, num_out_activation_maps], tf.float32,\n",
    "                                  tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32))\n",
    "        biases = tf.get_variable(\"bias\", [num_out_activation_maps], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv_layer = tf.nn.conv2d(input_tensor, weights, (1, stride_horizontal, stride_vertical, 1), padding='SAME')\n",
    "        activation = activation_fn(tf.nn.bias_add(conv_layer, biases))\n",
    "        return activation\n",
    "\n",
    "def fully_connected(input_tensor, name, output_neurons, activation_fn=tf.nn.relu):\n",
    "    n_in = input_tensor.get_shape()[-1].value\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('weights', [n_in, output_neurons], tf.float32,\n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32))\n",
    "        biases = tf.get_variable(\"bias\", [output_neurons], tf.float32, tf.constant_initializer(0.0))\n",
    "        logits = tf.nn.bias_add(tf.matmul(input_tensor, weights), biases)\n",
    "        if activation_fn is None:\n",
    "            return logits\n",
    "        return activation_fn(logits)\n",
    "\n",
    "def max_pool(input_tensor, name, kernel_height, kernel_width, stride_horizontal, stride_vertical):\n",
    "    return tf.nn.max_pool(input_tensor,\n",
    "                          ksize=[1, kernel_height, kernel_width, 1],\n",
    "                          strides=[1, stride_horizontal, stride_vertical, 1],\n",
    "                          padding='VALID',\n",
    "                          name=name)\n",
    "\n",
    "def loss(logits, onehot_labels):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=onehot_labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')\n",
    "    return loss\n",
    "\n",
    "# perform data augmentation on images\n",
    "# add random hue and saturation\n",
    "# randomly flip the image vertically and horizontally\n",
    "def augment_image(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.random_hue(image, 0.02)\n",
    "    image = tf.image.random_saturation(image, 0.9, 1.2)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return build_hsv_grayscale_image(image)\n",
    "\n",
    "# converts the image from RGB to HSV and\n",
    "# adds a 4th channel to the HSV ones that contains the image in gray scale\n",
    "# for test just convert the image to HSV and add the gray scale channel\n",
    "def build_hsv_grayscale_image(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    gray_image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    rez = tf.concat([image, gray_image], 2)\n",
    "    return rez\n",
    "    \n",
    "def update_learning_rate(acc, learn_rate):\n",
    "    return learn_rate - acc * learn_rate * 0.9\n",
    "\n",
    "def conv_net(input_layer, dropout):\n",
    "    # number of activation maps for each convolutional layer\n",
    "    number_of_act_maps_conv1 = 16\n",
    "    number_of_act_maps_conv2 = 32\n",
    "    number_of_act_maps_conv3 = 64\n",
    "    number_of_act_maps_conv4 = 128\n",
    "\n",
    "    # number of outputs for each fully connected layer\n",
    "    number_of_fcl_outputs1 = 1024\n",
    "    number_of_fcl_outputs2 = 256\n",
    "\n",
    "    input_layer = tf.reshape(input_layer, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, NETWORK_DEPTH])\n",
    "\n",
    "    conv1 = conv(input_layer, 'conv1', kernel_width=5, kernel_height=5, num_out_activation_maps=number_of_act_maps_conv1)\n",
    "    conv1 = max_pool(conv1, 'max_pool1', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
    "\n",
    "    conv2 = conv(conv1, 'conv2', kernel_width=5, kernel_height=5, num_out_activation_maps=number_of_act_maps_conv2)\n",
    "    conv2 = max_pool(conv2, 'max_pool2', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
    "\n",
    "    conv3 = conv(conv2, 'conv3', kernel_width=5, kernel_height=5, num_out_activation_maps=number_of_act_maps_conv3)\n",
    "    conv3 = max_pool(conv3, 'max_pool3', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
    "\n",
    "    conv4 = conv(conv3, 'conv4', kernel_width=5, kernel_height=5, num_out_activation_maps=number_of_act_maps_conv4)\n",
    "    conv4 = max_pool(conv4, 'max_pool4', kernel_height=2, kernel_width=2, stride_horizontal=2, stride_vertical=2)\n",
    "\n",
    "    flattened_shape = np.prod([s.value for s in conv4.get_shape()[1:]])\n",
    "    net = tf.reshape(conv4, [-1, flattened_shape], name=\"flatten\")\n",
    "\n",
    "    fcl1 = fully_connected(net, 'fcl1', number_of_fcl_outputs1)\n",
    "    fcl1 = tf.nn.dropout(fcl1, dropout)\n",
    "\n",
    "    fcl2 = fully_connected(fcl1, 'fcl2', number_of_fcl_outputs2)\n",
    "    fcl2 = tf.nn.dropout(fcl2, dropout)\n",
    "\n",
    "    out = fully_connected(fcl2, 'out', num_classes, activation_fn=None)\n",
    "    \n",
    "    print(\"conv1: %d\" % (number_of_act_maps_conv1))\n",
    "    print(\"conv2: %d\" % (number_of_act_maps_conv2))\n",
    "    print(\"conv3: %d\" % (number_of_act_maps_conv3))\n",
    "    print(\"conv4: %d\" % (number_of_act_maps_conv4))\n",
    "    print(\"fcl1: %d\" % (number_of_fcl_outputs1))\n",
    "    print(\"fcl2: %d\" % (number_of_fcl_outputs2))\n",
    "\n",
    "    return out\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def train_model(session, train_operation, loss_operation, correct_prediction, iterator_map):\n",
    "    global learning_rate\n",
    "    time1 = time.time()\n",
    "    train_iterator = iterator_map[\"train_iterator\"]\n",
    "    validation_iterator = iterator_map[\"validation_iterator\"]\n",
    "    validation_init_op = iterator_map[\"validation_init_op\"]\n",
    "    train_images_with_labels = train_iterator.get_next()\n",
    "    validation_images_with_labels = validation_iterator.get_next()\n",
    "    for i in range(1, iterations + 1):\n",
    "        batch_x, batch_y = session.run(train_images_with_labels)\n",
    "        batch_x = np.reshape(batch_x, [batch_size, input_size])\n",
    "        session.run(train_operation, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        if i % step_display == 0:\n",
    "            time2 = time.time()\n",
    "            print(\"time: %.4f step: %d\" % (time2 - time1, i))\n",
    "            time1 = time.time()\n",
    "\n",
    "        if i % display_interval == 0:\n",
    "            acc_value, loss = calculate_intermediate_accuracy_and_loss(session, correct_prediction, loss_operation,\n",
    "                                                                       validation_images_with_labels, validation_init_op, train_images_count)\n",
    "            learning_rate = update_learning_rate(acc_value, learn_rate=learning_rate)\n",
    "            print(\"step: %d loss: %.4f accuracy: %.4f\" % (i, loss, acc_value))\n",
    "        if i % save_interval == 0:\n",
    "            # save the weights and the meta data for the graph\n",
    "            saver.save(session, './model.ckpt')\n",
    "            tf.train.write_graph(session.graph_def,'./', 'graph.pbtxt')\n",
    "\n",
    "\n",
    "def calculate_intermediate_accuracy_and_loss(session, correct_prediction, loss_operation, test_images_with_labels, test_init_op, total_image_count):\n",
    "    sess.run(test_init_op)\n",
    "    loss = 0\n",
    "    predicted = 0\n",
    "    count = 0\n",
    "    total = 0\n",
    "    while total < total_image_count:\n",
    "        test_batch_x, test_batch_y = session.run(test_images_with_labels)\n",
    "        test_batch_x = np.reshape(test_batch_x, [-1, input_size])\n",
    "        l, p = session.run([loss_operation, correct_prediction], feed_dict={X: test_batch_x, Y: test_batch_y})\n",
    "        loss += l\n",
    "        predicted += np.sum(p)\n",
    "        count += 1\n",
    "        total += len(p)\n",
    "    return predicted / total_image_count, loss / count\n",
    "\n",
    "\n",
    "def test_model(sess, pred, iterator, total_images, file_name):\n",
    "    images_left_to_process = total_images\n",
    "    total_number_of_images = total_images\n",
    "    images_with_labels = iterator.get_next()\n",
    "    correct = 0\n",
    "    while images_left_to_process > 0:\n",
    "        batch_x, batch_y = sess.run(images_with_labels)\n",
    "        batch_x = np.reshape(batch_x, [-1, input_size])\n",
    "        # the results of the classification is an array of 1 and 0, 1 is a correct classification\n",
    "        results = sess.run(pred, feed_dict={X: batch_x, Y: batch_y})\n",
    "        images_left_to_process = images_left_to_process - len(results)\n",
    "        correct = correct + np.sum(results)\n",
    "        print(\"Predicted %d out of %d; partial accuracy %.4f\" % (correct, total_number_of_images - images_left_to_process,\n",
    "                                                                 correct / (total_number_of_images - images_left_to_process)))\n",
    "    print(\"Final accuracy on %s data: %.8f\" % (file_name, correct / total_number_of_images))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "train_images_count, fruit_labels = write_image_data(train_dir, \"train.tfrecord\")\n",
    "test_images_count, _ = write_image_data(validation_dir, \"test.tfrecord\")\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # placeholder for input layer\n",
    "    X = tf.placeholder(tf.float32, [None, input_size], name=\"X\")\n",
    "    # placeholder for actual labels\n",
    "    Y = tf.placeholder(tf.int64, [None], name=\"Y\")\n",
    "    \n",
    "    # build the network\n",
    "    logits = conv_net(input_layer=X, dropout=dropout)\n",
    "    # apply softmax on the final layer\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "    # calculate the loss using the predicted labels vs the expected labels\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "    # use adaptive moment estimation optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss=loss)\n",
    "    \n",
    "    # calculate the accuracy for this training step\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # input tfrecord file\n",
    "    train_file = \"train.tfrecord\"\n",
    "    test_file = \"test.tfrecord\"\n",
    "    train_dataset, validation_dataset, test_dataset = build_datasets(train_file, test_file, batch_size)\n",
    "    \n",
    "    train_iterator = train_dataset.make_one_shot_iterator()\n",
    "    validation_iterator = tf.data.Iterator.from_structure(validation_dataset.output_types, validation_dataset.output_shapes)\n",
    "    validation_init_op = validation_iterator.make_initializer(validation_dataset)\n",
    "    iterator_map = {\"train_iterator\": train_iterator,\n",
    "                    \"validation_iterator\": validation_iterator,\n",
    "                    \"validation_init_op\": validation_init_op}\n",
    "    test_iterator = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(init)\n",
    "    # restore the previously saved value if we wish to continue the training\n",
    "    if useCkpt:\n",
    "        ckpt = tf.train.get_checkpoint_state(\".\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    train_model(sess, train_op, loss, correct_prediction, iterator_map)\n",
    "    \n",
    "    test_model(sess, correct_prediction, test_iterator, test_images_count, test_file)\n",
    "    \n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
